{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error inicial 0.28447782649508807\n",
      "Epoch: 1\n",
      "Error: 0.040772651571327014\n",
      "Epoch: 2\n",
      "Error: 0.039309350406820626\n",
      "Epoch: 3\n",
      "Error: 0.037420874708529256\n",
      "Epoch: 4\n",
      "Error: 0.0352770238798144\n",
      "Epoch: 5\n",
      "Error: 0.03352686205778801\n",
      "Epoch: 6\n",
      "Error: 0.0316899455882679\n",
      "Epoch: 7\n",
      "Error: 0.029967284932310326\n",
      "Epoch: 8\n",
      "Error: 0.028462105248533192\n",
      "Epoch: 9\n",
      "Error: 0.02714156371715539\n",
      "Epoch: 10\n",
      "Error: 0.025940689623516616\n",
      "Epoch: 11\n",
      "Error: 0.02477606553853758\n",
      "Epoch: 12\n",
      "Error: 0.023566041430933042\n",
      "Epoch: 13\n",
      "Error: 0.022278356953629487\n",
      "Epoch: 14\n",
      "Error: 0.020950014855157427\n",
      "Epoch: 15\n",
      "Error: 0.019637044180705714\n",
      "Epoch: 16\n",
      "Error: 0.018461954507644474\n",
      "Epoch: 17\n",
      "Error: 0.017407765731565102\n",
      "Epoch: 18\n",
      "Error: 0.016442892345610888\n",
      "Epoch: 19\n",
      "Error: 0.01552064920530871\n",
      "Epoch: 20\n",
      "Error: 0.014712408498120074\n",
      "Epoch: 21\n",
      "Error: 0.014000954299945809\n",
      "Epoch: 22\n",
      "Error: 0.013363348327096281\n",
      "Epoch: 23\n",
      "Error: 0.012795324496684187\n",
      "Epoch: 24\n",
      "Error: 0.012283825507645625\n",
      "Epoch: 25\n",
      "Error: 0.011813725453192644\n",
      "Epoch: 26\n",
      "Error: 0.01137950214818452\n",
      "Epoch: 27\n",
      "Error: 0.010980039478903187\n",
      "Epoch: 28\n",
      "Error: 0.010601312671780324\n",
      "Epoch: 29\n",
      "Error: 0.01022975449904235\n",
      "Epoch: 30\n",
      "Error: 0.009859727122234504\n",
      "Epoch: 31\n",
      "Error: 0.00949225551861014\n",
      "Epoch: 32\n",
      "Error: 0.00913011410904294\n",
      "Epoch: 33\n",
      "Error: 0.008773664079341974\n",
      "Epoch: 34\n",
      "Error: 0.008421163799602177\n",
      "Epoch: 35\n",
      "Error: 0.00807232135362213\n",
      "Epoch: 36\n",
      "Error: 0.0077278837897135685\n",
      "Epoch: 37\n",
      "Error: 0.0073832736130315\n",
      "Epoch: 38\n",
      "Error: 0.007043034575707363\n",
      "Epoch: 39\n",
      "Error: 0.0067328381369310825\n",
      "Epoch: 40\n",
      "Error: 0.00643796649555559\n",
      "Epoch: 41\n",
      "Error: 0.0061697857550347575\n",
      "Epoch: 42\n",
      "Error: 0.0059304541047135355\n",
      "Epoch: 43\n",
      "Error: 0.005716564389754805\n",
      "Epoch: 44\n",
      "Error: 0.005523432379122855\n",
      "Epoch: 45\n",
      "Error: 0.005350900069945085\n",
      "Epoch: 46\n",
      "Error: 0.00519788595905203\n",
      "Epoch: 47\n",
      "Error: 0.005059359581680378\n",
      "Epoch: 48\n",
      "Error: 0.004930168179923683\n",
      "Epoch: 49\n",
      "Error: 0.004808277420234312\n",
      "Epoch: 50\n",
      "Error: 0.004693900121386197\n",
      "Epoch: 51\n",
      "Error: 0.004587703072520154\n",
      "Epoch: 52\n",
      "Error: 0.004489553623872726\n",
      "Epoch: 53\n",
      "Error: 0.0043955625079328126\n",
      "Epoch: 54\n",
      "Error: 0.004302813348256741\n",
      "Epoch: 55\n",
      "Error: 0.00421573428426928\n",
      "Epoch: 56\n",
      "Error: 0.004136065389909091\n",
      "Epoch: 57\n",
      "Error: 0.004062718604372849\n",
      "Epoch: 58\n",
      "Error: 0.003994793400588003\n",
      "Epoch: 59\n",
      "Error: 0.003931748394462694\n",
      "Epoch: 60\n",
      "Error: 0.003873081681128472\n",
      "Epoch: 61\n",
      "Error: 0.0038181742712018393\n",
      "Epoch: 62\n",
      "Error: 0.003766331208297754\n",
      "Epoch: 63\n",
      "Error: 0.003716854625834155\n",
      "Epoch: 64\n",
      "Error: 0.0036690550452165628\n",
      "Epoch: 65\n",
      "Error: 0.0036222122218057596\n",
      "Epoch: 66\n",
      "Error: 0.003575514048578129\n",
      "Epoch: 67\n",
      "Error: 0.003527989494631609\n",
      "Epoch: 68\n",
      "Error: 0.0034784555746817897\n",
      "Epoch: 69\n",
      "Error: 0.00342553417414493\n",
      "Epoch: 70\n",
      "Error: 0.003367863086662333\n",
      "Epoch: 71\n",
      "Error: 0.0033046520945376134\n",
      "Epoch: 72\n",
      "Error: 0.003236465811253141\n",
      "Epoch: 73\n",
      "Error: 0.0031654764771813617\n",
      "Epoch: 74\n",
      "Error: 0.0030945145565291427\n",
      "Epoch: 75\n",
      "Error: 0.0030256562570902304\n",
      "Epoch: 76\n",
      "Error: 0.0029594954530299793\n",
      "Epoch: 77\n",
      "Error: 0.0028954090785164683\n",
      "Epoch: 78\n",
      "Error: 0.0028326548977721166\n",
      "Epoch: 79\n",
      "Error: 0.0027712831922796573\n",
      "Epoch: 80\n",
      "Error: 0.00271110313361746\n",
      "Epoch: 81\n",
      "Error: 0.0026503054818215323\n",
      "Epoch: 82\n",
      "Error: 0.0025871403967901987\n",
      "Epoch: 83\n",
      "Error: 0.0025217015579666155\n",
      "Epoch: 84\n",
      "Error: 0.0024552762129261413\n",
      "Epoch: 85\n",
      "Error: 0.002389243014076837\n",
      "Epoch: 86\n",
      "Error: 0.0023246257555116162\n",
      "Epoch: 87\n",
      "Error: 0.0022620862187888906\n",
      "Epoch: 88\n",
      "Error: 0.002202061582271405\n",
      "Epoch: 89\n",
      "Error: 0.002144881883074519\n",
      "Epoch: 90\n",
      "Error: 0.0020907793374369023\n",
      "Epoch: 91\n",
      "Error: 0.002039826605919656\n",
      "Epoch: 92\n",
      "Error: 0.0019919381165335306\n",
      "Epoch: 93\n",
      "Error: 0.0019469474062115343\n",
      "Epoch: 94\n",
      "Error: 0.0019046686008124042\n",
      "Epoch: 95\n",
      "Error: 0.0018649157932786925\n",
      "Epoch: 96\n",
      "Error: 0.0018275058628451958\n",
      "Epoch: 97\n",
      "Error: 0.0017922628950087624\n",
      "Epoch: 98\n",
      "Error: 0.0017590267618441452\n",
      "Epoch: 99\n",
      "Error: 0.0017276611730342956\n",
      "Epoch: 100\n",
      "Error: 0.001698056399988255\n",
      "Epoch: 101\n",
      "Error: 0.0016701252071406076\n",
      "Epoch: 102\n",
      "Error: 0.0016437942456761358\n",
      "Epoch: 103\n",
      "Error: 0.0016189952211254008\n",
      "Epoch: 104\n",
      "Error: 0.0015956594216341062\n",
      "Epoch: 105\n",
      "Error: 0.001573716318816042\n",
      "Epoch: 106\n",
      "Error: 0.0015530942205198232\n",
      "Epoch: 107\n",
      "Error: 0.0015337204138648846\n",
      "Epoch: 108\n",
      "Error: 0.0015155199028689709\n",
      "Epoch: 109\n",
      "Error: 0.0014984138913724005\n",
      "Epoch: 110\n",
      "Error: 0.0014823197335543086\n",
      "Epoch: 111\n",
      "Error: 0.0014671529614620463\n",
      "Epoch: 112\n",
      "Error: 0.0014528305484421554\n",
      "Epoch: 113\n",
      "Error: 0.0014392740446647384\n",
      "Epoch: 114\n",
      "Error: 0.001426411679330837\n",
      "Epoch: 115\n",
      "Error: 0.0014141792522362336\n",
      "Epoch: 116\n",
      "Error: 0.0014025200948378262\n",
      "Epoch: 117\n",
      "Error: 0.0013913844926532989\n",
      "Epoch: 118\n",
      "Error: 0.0013807288826656304\n",
      "Epoch: 119\n",
      "Error: 0.0013705150180375622\n",
      "Epoch: 120\n",
      "Error: 0.00136070919555131\n",
      "Epoch: 121\n",
      "Error: 0.0013512815814218438\n",
      "Epoch: 122\n",
      "Error: 0.0013422056400573198\n",
      "Epoch: 123\n",
      "Error: 0.0013334576567199906\n",
      "Epoch: 124\n",
      "Error: 0.0013250163406085826\n",
      "Epoch: 125\n",
      "Error: 0.001316862494721091\n",
      "Epoch: 126\n",
      "Error: 0.0013089787403783731\n",
      "Epoch: 127\n",
      "Error: 0.0013013492862591128\n",
      "Epoch: 128\n",
      "Error: 0.00129395973368841\n",
      "Epoch: 129\n",
      "Error: 0.0012867969115502396\n",
      "Epoch: 130\n",
      "Error: 0.0012798487355254109\n",
      "Epoch: 131\n",
      "Error: 0.001273104087418524\n",
      "Epoch: 132\n",
      "Error: 0.0012665527111747942\n",
      "Epoch: 133\n",
      "Error: 0.001260185122845499\n",
      "Epoch: 134\n",
      "Error: 0.0012539925322782488\n",
      "Epoch: 135\n",
      "Error: 0.0012479667747167947\n",
      "Epoch: 136\n",
      "Error: 0.0012421002508192854\n",
      "Epoch: 137\n",
      "Error: 0.001236385873862811\n",
      "Epoch: 138\n",
      "Error: 0.001230817023110138\n",
      "Epoch: 139\n",
      "Error: 0.0012253875024828577\n",
      "Epoch: 140\n",
      "Error: 0.0012200915038221845\n",
      "Epoch: 141\n",
      "Error: 0.0012149235741308172\n",
      "Epoch: 142\n",
      "Error: 0.0012098785862816816\n",
      "Epoch: 143\n",
      "Error: 0.0012049517127558464\n",
      "Epoch: 144\n",
      "Error: 0.0012001384020355623\n",
      "Epoch: 145\n",
      "Error: 0.0011954343573315547\n",
      "Epoch: 146\n",
      "Error: 0.001190835517368385\n",
      "Epoch: 147\n",
      "Error: 0.0011863380389893297\n",
      "Epoch: 148\n",
      "Error: 0.001181938281374096\n",
      "Epoch: 149\n",
      "Error: 0.0011776327916897652\n",
      "Epoch: 150\n",
      "Error: 0.0011734182920184013\n",
      "Epoch: 151\n",
      "Error: 0.0011692916674244935\n",
      "Epoch: 152\n",
      "Error: 0.0011652499550423247\n",
      "Epoch: 153\n",
      "Error: 0.0011612903340778788\n",
      "Epoch: 154\n",
      "Error: 0.0011574101166324853\n",
      "Epoch: 155\n",
      "Error: 0.0011536067392662283\n",
      "Epoch: 156\n",
      "Error: 0.0011498777552285656\n",
      "Epoch: 157\n",
      "Error: 0.0011462208272918007\n",
      "Epoch: 158\n",
      "Error: 0.001142633721130149\n",
      "Epoch: 159\n",
      "Error: 0.0011391142991933898\n",
      "Epoch: 160\n",
      "Error: 0.0011356605150295246\n",
      "Epoch: 161\n",
      "Error: 0.001132270408015638\n",
      "Epoch: 162\n",
      "Error: 0.0011289420984603462\n",
      "Epoch: 163\n",
      "Error: 0.0011256737830449002\n",
      "Epoch: 164\n",
      "Error: 0.001122463730573263\n",
      "Epoch: 165\n",
      "Error: 0.001119310278004323\n",
      "Epoch: 166\n",
      "Error: 0.0011162118267419418\n",
      "Epoch: 167\n",
      "Error: 0.0011131668391607503\n",
      "Epoch: 168\n",
      "Error: 0.0011101738353475677\n",
      "Epoch: 169\n",
      "Error: 0.0011072313900400538\n",
      "Epoch: 170\n",
      "Error: 0.001104338129745711\n",
      "Epoch: 171\n",
      "Error: 0.0011014927300256965\n",
      "Epoch: 172\n",
      "Error: 0.0010986939129290624\n",
      "Epoch: 173\n",
      "Error: 0.0010959404445640385\n",
      "Epoch: 174\n",
      "Error: 0.0010932311327938465\n",
      "Epoch: 175\n",
      "Error: 0.0010905648250452522\n",
      "Epoch: 176\n",
      "Error: 0.0010879404062186522\n",
      "Epoch: 177\n",
      "Error: 0.0010853567966889754\n",
      "Epoch: 178\n",
      "Error: 0.0010828129503870003\n",
      "Epoch: 179\n",
      "Error: 0.0010803078529509286\n",
      "Epoch: 180\n",
      "Error: 0.001077840519938126\n",
      "Epoch: 181\n",
      "Error: 0.0010754099950868764\n",
      "Epoch: 182\n",
      "Error: 0.001073015348617811\n",
      "Epoch: 183\n",
      "Error: 0.0010706556755642564\n",
      "Epoch: 184\n",
      "Error: 0.0010683300941202098\n",
      "Epoch: 185\n",
      "Error: 0.0010660377439938179\n",
      "Epoch: 186\n",
      "Error: 0.001063777784753202\n",
      "Epoch: 187\n",
      "Error: 0.0010615493941500951\n",
      "Epoch: 188\n",
      "Error: 0.0010593517664050176\n",
      "Epoch: 189\n",
      "Error: 0.0010571841104355289\n",
      "Epoch: 190\n",
      "Error: 0.0010550456480063538\n",
      "Epoch: 191\n",
      "Error: 0.0010529356117767636\n",
      "Epoch: 192\n",
      "Error: 0.0010508532432163251\n",
      "Epoch: 193\n",
      "Error: 0.001048797790354815\n",
      "Epoch: 194\n",
      "Error: 0.001046768505325453\n",
      "Epoch: 195\n",
      "Error: 0.0010447646416522798\n",
      "Epoch: 196\n",
      "Error: 0.0010427854512220333\n",
      "Epoch: 197\n",
      "Error: 0.001040830180867671\n",
      "Epoch: 198\n",
      "Error: 0.0010388980684738983\n",
      "Epoch: 199\n",
      "Error: 0.0010369883384937237\n",
      "Epoch: 200\n",
      "Error: 0.0010351001967376307\n",
      "Epoch: 201\n",
      "Error: 0.0010332328242616362\n",
      "Epoch: 202\n",
      "Error: 0.0010313853701346314\n",
      "Epoch: 203\n",
      "Error: 0.0010295569428054499\n",
      "Epoch: 204\n",
      "Error: 0.0010277465997112097\n",
      "Epoch: 205\n",
      "Error: 0.0010259533346637921\n",
      "Epoch: 206\n",
      "Error: 0.0010241760624113692\n",
      "Epoch: 207\n",
      "Error: 0.0010224135995831275\n",
      "Epoch: 208\n",
      "Error: 0.0010206646409684794\n",
      "Epoch: 209\n",
      "Error: 0.0010189277297291866\n",
      "Epoch: 210\n",
      "Error: 0.0010172012196532098\n",
      "Epoch: 211\n",
      "Error: 0.0010154832268725205\n",
      "Epoch: 212\n",
      "Error: 0.001013771567493669\n",
      "Epoch: 213\n",
      "Error: 0.0010120636761934338\n",
      "Epoch: 214\n",
      "Error: 0.0010103564988040285\n",
      "Epoch: 215\n",
      "Error: 0.0010086463489295814\n",
      "Epoch: 216\n",
      "Error: 0.0010069287141895894\n",
      "Epoch: 217\n",
      "Error: 0.0010051979909661236\n",
      "Epoch: 218\n",
      "Error: 0.0010034471162344968\n",
      "Epoch: 219\n",
      "Error: 0.0010016670490538518\n",
      "Epoch: 220\n",
      "Error: 0.0009998460290843426\n",
      "Epoch: 221\n",
      "Error: 0.0009979684992982576\n",
      "Epoch: 222\n",
      "Error: 0.0009960135153459229\n",
      "Epoch: 223\n",
      "Error: 0.000993952359470075\n",
      "Epoch: 224\n",
      "Error: 0.0009917449089994644\n",
      "Epoch: 225\n",
      "Error: 0.0009893340475335475\n",
      "Epoch: 226\n",
      "Error: 0.000986637029398007\n",
      "Epoch: 227\n",
      "Error: 0.0009835322794069072\n",
      "Epoch: 228\n",
      "Error: 0.0009798400589967455\n",
      "Epoch: 229\n",
      "Error: 0.0009752974055947045\n",
      "Epoch: 230\n",
      "Error: 0.000969536729149722\n",
      "Epoch: 231\n",
      "Error: 0.0009621042516785466\n",
      "Epoch: 232\n",
      "Error: 0.0009526053284274975\n",
      "Epoch: 233\n",
      "Error: 0.0009410703356657755\n",
      "Epoch: 234\n",
      "Error: 0.0009283633831594858\n",
      "Epoch: 235\n",
      "Error: 0.0009159763697276897\n",
      "Epoch: 236\n",
      "Error: 0.0009050612373401316\n",
      "Epoch: 237\n",
      "Error: 0.0008958668799090847\n",
      "Epoch: 238\n",
      "Error: 0.0008880911915020859\n",
      "Epoch: 239\n",
      "Error: 0.0008813575463942753\n",
      "Epoch: 240\n",
      "Error: 0.0008753950616715896\n",
      "Epoch: 241\n",
      "Error: 0.0008700447484933648\n",
      "Epoch: 242\n",
      "Error: 0.0008652210712529028\n",
      "Epoch: 243\n",
      "Error: 0.0008608706283503377\n",
      "Epoch: 244\n",
      "Error: 0.0008569410660563357\n",
      "Epoch: 245\n",
      "Error: 0.000853369175304431\n",
      "Epoch: 246\n",
      "Error: 0.0008500873529269504\n",
      "Epoch: 247\n",
      "Error: 0.0008470357325672818\n",
      "Epoch: 248\n",
      "Error: 0.0008441684156277852\n",
      "Epoch: 249\n",
      "Error: 0.0008414525564708565\n",
      "Epoch: 250\n",
      "Error: 0.0008388646593630239\n",
      "Epoch: 251\n",
      "Error: 0.0008363872781991205\n",
      "Epoch: 252\n",
      "Error: 0.0008340068905540255\n",
      "Epoch: 253\n",
      "Error: 0.0008317126609617719\n",
      "Epoch: 254\n",
      "Error: 0.0008294957094471802\n",
      "Epoch: 255\n",
      "Error: 0.0008273486459893754\n",
      "Epoch: 256\n",
      "Error: 0.000825265250177224\n",
      "Epoch: 257\n",
      "Error: 0.0008232402376920966\n",
      "Epoch: 258\n",
      "Error: 0.0008212690837257492\n",
      "Epoch: 259\n",
      "Error: 0.0008193478862846509\n",
      "Epoch: 260\n",
      "Error: 0.0008174732585902321\n",
      "Epoch: 261\n",
      "Error: 0.0008156422432323297\n",
      "Epoch: 262\n",
      "Error: 0.0008138522428641226\n",
      "Epoch: 263\n",
      "Error: 0.0008121009636510891\n",
      "Epoch: 264\n",
      "Error: 0.0008103863686814558\n",
      "Epoch: 265\n",
      "Error: 0.0008087066392575767\n",
      "Epoch: 266\n",
      "Error: 0.0008070601425042837\n",
      "Epoch: 267\n",
      "Error: 0.0008054454041085558\n",
      "Epoch: 268\n",
      "Error: 0.0008038610852834627\n",
      "Epoch: 269\n",
      "Error: 0.0008023059632550908\n",
      "Epoch: 270\n",
      "Error: 0.0008007789147230207\n",
      "Epoch: 271\n",
      "Error: 0.0007992789018565947\n",
      "Epoch: 272\n",
      "Error: 0.0007978049604708185\n",
      "Epoch: 273\n",
      "Error: 0.000796356190085056\n",
      "Epoch: 274\n",
      "Error: 0.000794931745610688\n",
      "Epoch: 275\n",
      "Error: 0.000793530830445453\n",
      "Epoch: 276\n",
      "Error: 0.0007921526907760004\n",
      "Epoch: 277\n",
      "Error: 0.0007907966109092317\n",
      "Epoch: 278\n",
      "Error: 0.0007894619094694378\n",
      "Epoch: 279\n",
      "Error: 0.0007881479363135282\n",
      "Epoch: 280\n",
      "Error: 0.0007868540700317108\n",
      "Epoch: 281\n",
      "Error: 0.0007855797159161831\n",
      "Epoch: 282\n",
      "Error: 0.0007843243042957706\n",
      "Epoch: 283\n",
      "Error: 0.0007830872891497433\n",
      "Epoch: 284\n",
      "Error: 0.0007818681469289017\n",
      "Epoch: 285\n",
      "Error: 0.0007806663755260169\n",
      "Epoch: 286\n",
      "Error: 0.0007794814933504853\n",
      "Epoch: 287\n",
      "Error: 0.0007783130384733351\n",
      "Epoch: 288\n",
      "Error: 0.0007771605678183246\n",
      "Epoch: 289\n",
      "Error: 0.0007760236563827885\n",
      "Epoch: 290\n",
      "Error: 0.0007749018964781188\n",
      "Epoch: 291\n",
      "Error: 0.0007737948969845119\n",
      "Epoch: 292\n",
      "Error: 0.0007727022826180245\n",
      "Epoch: 293\n",
      "Error: 0.0007716236932102473\n",
      "Epoch: 294\n",
      "Error: 0.0007705587830023296\n",
      "Epoch: 295\n",
      "Error: 0.0007695072199557817\n",
      "Epoch: 296\n",
      "Error: 0.0007684686850826976\n",
      "Epoch: 297\n",
      "Error: 0.0007674428717979145\n",
      "Epoch: 298\n",
      "Error: 0.0007664294852952723\n",
      "Epoch: 299\n",
      "Error: 0.0007654282419496839\n",
      "Epoch: 300\n",
      "Error: 0.0007644388687462143\n",
      "En la foto a predecir de:  ad , predijo:  ad Ok\n",
      "En la foto a predecir de:  cp , predijo:  gf \n",
      "En la foto a predecir de:  ec , predijo:  ec Ok\n",
      "En la foto a predecir de:  ep , predijo:  ep Ok\n",
      "En la foto a predecir de:  fh , predijo:  fh Ok\n",
      "En la foto a predecir de:  gf , predijo:  gf Ok\n",
      "En la foto a predecir de:  hg , predijo:  hg Ok\n",
      "En la foto a predecir de:  ja , predijo:  ja Ok\n",
      "En la foto a predecir de:  jm , predijo:  jm Ok\n",
      "En la foto a predecir de:  jp , predijo:  fh \n",
      "En la foto a predecir de:  jt , predijo:  jt Ok\n",
      "En la foto a predecir de:  lm , predijo:  lm Ok\n",
      "En la foto a predecir de:  mf , predijo:  ja \n",
      "En la foto a predecir de:  mg , predijo:  mg Ok\n",
      "En la foto a predecir de:  mk , predijo:  mk Ok\n",
      "En la foto a predecir de:  ml , predijo:  ml Ok\n",
      "En la foto a predecir de:  mt , predijo:  mt Ok\n",
      "En la foto a predecir de:  nl , predijo:  nl Ok\n",
      "En la foto a predecir de:  ob , predijo:  ob Ok\n",
      "En la foto a predecir de:  rb , predijo:  rb Ok\n",
      "En la foto a predecir de:  re , predijo:  re Ok\n",
      "En la foto a predecir de:  sp , predijo:  sp Ok\n",
      "En la foto a predecir de:  ss , predijo:  ss Ok\n",
      "La cantidad de predicciones correctas fueron  20  de  23\n",
      "    Foto  Clase Real Clase Predicha  Predicción Correcta\n",
      "0      1      Andres         Andres                 True\n",
      "1      2     Claudia       Geronimo                False\n",
      "2      3      Elemir         Elemir                 True\n",
      "3      4     Eduardo        Eduardo                 True\n",
      "4      5    Fernanda       Fernanda                 True\n",
      "5      6    Geronimo       Geronimo                 True\n",
      "6      7      Hernan         Hernan                 True\n",
      "7      8     Julieta        Julieta                 True\n",
      "8      9       Jiang          Jiang                 True\n",
      "9     10    Josefina       Fernanda                False\n",
      "10    11     Joaquin        Joaquin                 True\n",
      "11    12       Lujan          Lujan                 True\n",
      "12    13     Maribel        Julieta                False\n",
      "13    14  Marcelo G.     Marcelo G.                 True\n",
      "14    15      Marisa         Marisa                 True\n",
      "15    16       Maira          Maira                 True\n",
      "16    17  Marcelo T.     Marcelo T.                 True\n",
      "17    18      Nestor         Nestor                 True\n",
      "18    19       Oscar          Oscar                 True\n",
      "19    20       Ramon          Ramon                 True\n",
      "20    21     Rodrigo        Rodrigo                 True\n",
      "21    22   Sebastian      Sebastian                 True\n",
      "22    23      Silvia         Silvia                 True\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.preprocessing import standardize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def func_eval(fname, x):\n",
    "    match fname:\n",
    "        case \"purelin\":\n",
    "            y = x\n",
    "        case \"logsig\":\n",
    "            y = 1.0 / ( 1.0 + math.exp(-x) )\n",
    "        case \"tansig\":\n",
    "            y = 2.0 / ( 1.0 + math.exp(-2.0*x) ) - 1.0\n",
    "    return y\n",
    "\n",
    "def deriv_eval(fname, y):  # Atención que y es la entrada y=f( x )\n",
    "    match fname:\n",
    "        case \"purelin\":\n",
    "            d = 1.0\n",
    "        case \"logsig\":\n",
    "            d = y*(1.0-y)\n",
    "        case \"tansig\":\n",
    "            d = 1.0 - y*y\n",
    "    return d \n",
    "\n",
    "# Vectorizar la función para poder pasarle un vector para los cálculos\n",
    "func_eval_vec = np.vectorize(func_eval)\n",
    "\n",
    "# Vectorizar la función para poder pasarle un vector para los cálculos\n",
    "deriv_eval_vec = np.vectorize(deriv_eval)\n",
    "\n",
    "entrada = np.load(\"x_pca_reduc.npy\")\n",
    "# Pasar las listas a numpy\n",
    "X = np.array(entrada)\n",
    "\n",
    "# Lectura de archivo con nombres (var respuesta)\n",
    "nombres = np.load(\"nombres.npy\")\n",
    "\n",
    "# Convertir los valores de la var categórica en números\n",
    "Y = LabelBinarizer().fit_transform(nombres)\n",
    "\n",
    "# Definición de parámetros de la red neuronal\n",
    "filas_qty = len(X)\n",
    "input_size = X.shape[1]   # 2 entradas\n",
    "hidden_size = 10          # neuronas capa oculta\n",
    "output_size = Y.shape[1]  # neuronas de salida\n",
    "\n",
    "# Definir las funciones de activación de cada capa\n",
    "hidden_FUNC = 'logsig'  # usamos la logistica\n",
    "output_FUNC = 'logsig'  # usamos la logistica\n",
    "\n",
    "# Incializar las matrices de pesos azarosamente\n",
    "# W1 son los pesos que van del input a la capa oculta\n",
    "# W2 son los pesos que van de la capa oculta a la capa de salida\n",
    "np.random.seed(1021) # Usamos la querida random seed Denicolay para que las corridas sean reproducibles\n",
    "\n",
    "W1 = np.random.uniform(-0.5, 0.5, [hidden_size, input_size])\n",
    "X01 = np.random.uniform(-0.5, 0.5, [hidden_size, 1] )\n",
    "W2 = np.random.uniform(-0.5, 0.5, [output_size, hidden_size])\n",
    "X02 = np.random.uniform(-0.5, 0.5, [output_size, 1] )\n",
    "\n",
    "# Avanzar en la red, forward\n",
    "# para TODOS los X al mismo tiempo ! \n",
    "#  @ hace el producto de una matrix por un vector_columna\n",
    "hidden_estimulos = W1 @ X.T + X01\n",
    "# hidden_estimulos = hidden_estimulos.round(3)\n",
    "hidden_salidas = func_eval_vec(hidden_FUNC, hidden_estimulos)\n",
    "output_estimulos = W2 @ hidden_salidas + X02\n",
    "output_salidas = func_eval_vec(output_FUNC, output_estimulos)\n",
    "\n",
    "# Calcular el error promedio general de TODOS los X\n",
    "Error= np.mean( (Y.T - output_salidas)**2 )\n",
    "print(f\"Error inicial {Error}\")\n",
    "\n",
    "# Inicializar\n",
    "epoch_limit = 2000    # Para terminar si no converge\n",
    "Error_umbral = 1.0e-06\n",
    "learning_rate = 0.3\n",
    "Error_last = 10    # Poner algo dist a 0 la primera vez\n",
    "epoch = 0\n",
    "\n",
    "while ( math.fabs(Error_last-Error)>Error_umbral and (epoch < epoch_limit)):\n",
    "    epoch += 1\n",
    "    Error_last = Error\n",
    "\n",
    "    # Recorrer siempre TODA la entrada\n",
    "    for fila in range(filas_qty): # Para cada input x_sub_fila del vector X\n",
    "        # Propagar el x hacia adelante\n",
    "        hidden_estimulos = W1 @ X[fila:fila+1, :].T + X01\n",
    "        hidden_salidas = func_eval_vec(hidden_FUNC, hidden_estimulos)\n",
    "        output_estimulos = W2 @ hidden_salidas + X02\n",
    "        output_salidas = func_eval_vec(output_FUNC, output_estimulos)\n",
    "\n",
    "        # Calcular los errores en la capa hidden y la capa output\n",
    "        ErrorSalida = Y[fila:fila+1,:].T - output_salidas\n",
    "        # output_delta es un sólo número\n",
    "        output_delta = ErrorSalida * deriv_eval_vec(output_FUNC, output_salidas)\n",
    "        # hidden_delta es un vector columna\n",
    "        hidden_delta = deriv_eval_vec(hidden_FUNC, hidden_salidas)*(W2.T @ output_delta)\n",
    "\n",
    "        # Ya tenemos los errores que comete cada capa\n",
    "        # corregir matrices de pesos, vamos hacia atrás\n",
    "        # backpropagation\n",
    "        W1 = W1 + learning_rate * (hidden_delta @ X[fila:fila+1, :] )\n",
    "        X01 = X01 + learning_rate * hidden_delta\n",
    "        W2 = W2 + learning_rate * (output_delta @ hidden_salidas.T)\n",
    "        X02 = X02 + learning_rate * output_delta\n",
    "\n",
    "    # Ya recalculamos las matrices de pesos\n",
    "    # ahora avanzamos la red, feed-forward\n",
    "    hidden_estimulos = W1 @ X.T + X01\n",
    "    hidden_salidas = func_eval_vec(hidden_FUNC, hidden_estimulos)\n",
    "    output_estimulos = W2 @ hidden_salidas + X02\n",
    "    output_salidas = func_eval_vec(output_FUNC, output_estimulos)\n",
    "\n",
    "    # Calcular el error promedio general de TODOS los X\n",
    "    Error= np.mean( (Y.T - output_salidas)**2 )\n",
    "    \n",
    "    print(\"Epoch:\", epoch)\n",
    "    print(\"Error:\", Error)\n",
    "    \n",
    "# Lectura de archivo con var target\n",
    "X_test = np.load(\"x_pca_test_reduc.npy\")\n",
    "\n",
    "# Lectura de archivo con nombres (var respuesta)\n",
    "nombres_test = np.load(\"nombres_test.npy\")\n",
    "\n",
    "# Convertir los valores de la var categórica en números\n",
    "y_test = LabelBinarizer().fit_transform(nombres_test)\n",
    "\n",
    "# Son los distintos nombres\n",
    "nom = np.unique(nombres)\n",
    "\n",
    "rta_ok = 0\n",
    "\n",
    "# Realizamos predicciones de 23 fotos nuevas de testeo que no se encontraban en el set \n",
    "# de datos del entrenamiento\n",
    "\n",
    "for fila in range(X_test.shape[0]):\n",
    "    \n",
    "    # Realizamos el cálculo utilizando las matrices óptimas W1 y W2\n",
    "    hidden_estimulos_predict = W1 @ X_test[fila:fila + 1, :].T + X01\n",
    "    hidden_salidas_predict = func_eval_vec(hidden_FUNC, hidden_estimulos_predict)\n",
    "    output_estimulos_predict = W2 @ hidden_salidas_predict + X02\n",
    "    output_salidas_predict = func_eval_vec(output_FUNC, output_estimulos_predict)\n",
    "\n",
    "    # Obtenemos el nombre correspondiente al registro de la foto a la salida de la red\n",
    "    pos_max = np.argmax(output_salidas_predict) \n",
    "\n",
    "    #print(\"posicion de lo estimado\",pos_max)\n",
    "    #print(\"posic en y_test\",np.argmax(y_test[fila]))\n",
    "    \n",
    "    \n",
    "    if ( nom[np.argmax(y_test[fila])] == nom[pos_max]):\n",
    "        rta_predic = \"Ok\"\n",
    "        rta_ok = rta_ok + 1\n",
    "    else:\n",
    "        rta_predic = \"\"\n",
    "\n",
    "    print(\"En la foto a predecir de: \", nom[np.argmax(y_test[fila])], \", predijo: \",nom[pos_max], rta_predic)\n",
    "\n",
    "\n",
    "print(\"La cantidad de predicciones correctas fueron \", rta_ok, \" de \", X_test.shape[0] )\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Crear una lista para almacenar los resultados de cada predicción\n",
    "resultados = []\n",
    "\n",
    "for fila in range(X_test.shape[0]):\n",
    "    # Realizar la predicción\n",
    "    hidden_estimulos_predict = W1 @ X_test[fila:fila + 1, :].T + X01\n",
    "    hidden_salidas_predict = func_eval_vec(hidden_FUNC, hidden_estimulos_predict)\n",
    "    output_estimulos_predict = W2 @ hidden_salidas_predict + X02\n",
    "    output_salidas_predict = func_eval_vec(output_FUNC, output_estimulos_predict)\n",
    "    pos_max = np.argmax(output_salidas_predict)\n",
    "\n",
    "    # Verificar si la predicción es correcta\n",
    "    prediccion_correcta = nom[np.argmax(y_test[fila])] == nom[pos_max]\n",
    "    \n",
    "    # Agregar el resultado a la lista\n",
    "    resultados.append({'Foto': fila+1,\n",
    "                       'Clase Real': nom[np.argmax(y_test[fila])],\n",
    "                       'Clase Predicha': nom[pos_max],\n",
    "                       'Predicción Correcta': prediccion_correcta})\n",
    "\n",
    "# Crear la tabla con los resultados\n",
    "tabla_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Reemplazar los valores de las etiquetas\n",
    "nuevos_valores = {'ad': 'Andres', 'cp': 'Claudia','ec': 'Elemir','ep': 'Eduardo','fh': 'Fernanda','gf': 'Geronimo','hg': 'Hernan','ja': 'Julieta','jm': 'Jiang','jp': 'Josefina','jt': 'Joaquin','lm': 'Lujan','mf': 'Maribel','mg': 'Marcelo G.','mk': 'Marisa','ml': 'Maira','mt': 'Marcelo T.','nl': 'Nestor','ob': 'Oscar','rb': 'Ramon','re': 'Rodrigo','sp': 'Sebastian','ss': 'Silvia'}\n",
    "tabla_resultados['Clase Real'].replace(nuevos_valores, inplace=True)\n",
    "tabla_resultados['Clase Predicha'].replace(nuevos_valores, inplace=True)\n",
    "\n",
    "# Mostrar la tabla\n",
    "print(tabla_resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
